<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>AI Risks &amp; Ethical Considerations - AI Literacy for Students</title>
    <link href="https://fonts.googleapis.com" rel="preconnect" />
    <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha512-SnH5WK+bZxgPHs44uWIX+LLJAJ9/2PkPKZ5QiAj6Ta86w+fsb2TkcmfRyVX3pBnMFcV7oQPJkl9QevSCWr3W6A==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="styles.css" />
</head>
<body>
<header class="site-header">
    <div class="site-header__inner">
        <a class="site-header__title" href="pillars-of-ai-literacy.html">AI Literacy for Students</a>
        <p class="site-header__tagline">Understand, explore, and apply generative AI responsibly.</p>
    </div>
</header>
<nav class="site-nav" aria-label="Primary">
    <ul class="site-nav__list">
        <li class='site-nav__item'>
            <a href='pillars-of-ai-literacy.html'>Pillars of AI Literacy</a>
        </li>
        <li class='site-nav__item site-nav__item--has-children'>
            <a href='authentic-learning-and-ai-use.html'>Authentic Learning and AI Use</a>
            <ul class='site-nav__sublist'>
                <li class='site-nav__subitem'><a href='learning-is-hard-and-its-supposed-to-be.html'>Learning is Hard - and it's supposed to be</a></li>
            </ul>
        </li>
        <li class='site-nav__item site-nav__item--has-children'>
            <a href='understand-and-explore-generative-ai.html'>Understand and Explore Generative AI</a>
            <ul class='site-nav__sublist'>
                <li class='site-nav__subitem'><a href='gen-ai-fundamentals.html'>Gen AI Fundamentals</a></li>
                <li class='site-nav__subitem'><a href='gen-ai-behind-the-curtain.html'>Gen AI - Behind the Curtain</a></li>
                <li class='site-nav__subitem'><a href='gen-ai-tools-platforms-and-interfaces.html'>Gen AI Tools, Platforms, and Interfaces</a></li>
                <li class='site-nav__subitem'><a href='potential-and-limitations-of-gen-ai.html'>Potential and Limitations of Gen AI</a></li>
            </ul>
        </li>
        <li class='site-nav__item site-nav__item--has-children site-nav__item--active'>
            <a href='analyze-and-apply-gen-ai.html'>Analyze and Apply Gen AI</a>
            <ul class='site-nav__sublist'>
                <li class='site-nav__subitem'><a href='essentials-for-smart-engagement.html'>Essentials for Smart Engagement</a></li>
                <li class='site-nav__subitem'><a href='ai-quick-queries-and-idea-sparker.html'>AI Quick Queries & Idea Sparker</a></li>
                <li class='site-nav__subitem'><a href='ai-study-buddy-and-skill-builder.html'>AI Study Buddy & Skill Builder</a></li>
                <li class='site-nav__subitem'><a href='ai-generated-writing-effective-and-ethical-use.html'>AI-Generated Writing: Effective and Ethical Use</a></li>
                <li class='site-nav__subitem'><a href='ai-research-assistants.html'>AI Research Assistants</a></li>
                <li class='site-nav__subitem site-nav__subitem--active'><a href='ai-risks-and-ethical-considerations.html'>AI Risks & Ethical Considerations</a></li>
                <li class='site-nav__subitem'><a href='ais-jagged-frontier.html'>AI's Jagged Frontier</a></li>
            </ul>
        </li>
        <li class='site-nav__item'>
            <a href='ai-contribution-statement.html'>AI Contribution Statement</a>
        </li>
    </ul>
</nav>
<div id="gai-wrap">
    <main>
        <div class="gai-cont">
        <section class="gai-box">
            <h2>AI Risks &amp; Ethical Considerations</h2>
            <div>

            <div>
            <h1>AI Risks and Ethical Impacts</h1>

            <div>
        </section>
        <section class="gai-box">
            <h2><i></i>Introduction: A Structured Lens</h2>
            <p>To use AI responsibly, you need to see understand its potential and its risks. The examples below will help you see some of the biggest risks and ethical dilemmas presented by AI. We will look at each example through a simple framework of its</p>

            <ul>
            	<li>severity: how bad is the impact</li>
            	<li> exposure: who or how much of the population is at risk</li>
            	<li>plausibility: how likely that we will see any impacts</li>
            	<li>prevalence: how often we are seeing impacts.</li>
            </ul>

            <p>Please note, that this is not a comprehensive list. If you have ideas of things that are missed, please reach out to the author.</p>

            <p>After working through these examples, hopefully you will see the interconnectivity of the risks and have a bit of an understanding of what you can do and what needs to be done to mitigate them.</p>
            </div>

            <div>
            <details><summary> <i></i> Information Integrity &amp; Civic Harms </summary>

            <div>
            <div><img alt="Abstract digital art showing a network of nodes being fractured by chaotic red lines, representing misinformation." loading="lazy" src="https://d1qywhc7l90rsa.cloudfront.net/accounts/165495/images/Info_Integrity_and_Civic_Harms.png"></div>

            <p>AI makes it easy to create and spread fake content. This can be anything from deepfakes to targeted propaganda. The result is a loss of trust, confusion, and rising social tension.</p>

            <p><strong>Example:</strong> A doctored video of a local candidate circulates before an election, changing public opinion before it can be debunked.</p>


            <table>
            	<thead>
            		<tr>
            			<th>Factor</th>
            			<th>Assessment</th>
            		</tr>
            	</thead>
            	<tbody>
            		<tr>
            			<td><span><i></i><strong>Severity</strong></span></td>
            			<td>High. Harms can impact public safety, elections, and trust in institutions.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Exposure</strong></span></td>
            			<td>Broad. Content can reach huge audiences very quickly.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Plausibility</strong></span></td>
            			<td>High. Tools for creating synthetic media are widely available.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Prevalence</strong></span></td>
            			<td>Increasing. Misinformation campaigns appear in every election cycle.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Mitigation</strong></span></td>
            			<td>
            			<p><strong>Systemic &amp; Institutional:</strong> Platforms can help by adding content labels, implementing strong guardrails, and using rapid fact-checking.</p>

            			<p><strong>Individual &amp; Classroom Actions:</strong></p>

            			<ul>
            				<li>Read laterally. When you see a claim, open new tabs to check it against other reliable sources.</li>
            				<li>Check the source. Use reverse image search to find a photo&#x27;s origin.</li>
            				<li>Pause before you post. Always verify information before you share it, especially if it makes you feel a strong emotion.</li>
            			</ul>
            			</td>
            		</tr>
            	</tbody>
            </table>

            <div>
            <h4><i></i>Quick Activity</h4>

            <p>Pick a trending video or post. Trace its source, check fact-checks, and look for content credentials. Discuss how one small edit could flip its meaning.</p>
            </div>

            <div>
            <h5><i></i>Dive Deeper</h5>

            <p>1) <a href="https://www.cisa.gov/sites/default/files/2024-10/PSA_Just_So_You_Know_Foreign_Threat_Actors_Likely_to_Use_a_Variety_of_TacticsV2-508.pdf" rel="noopener" target="_blank">CISA, Deepfakes &amp; Synthetic Media</a><br>
            2) <a href="https://syntheticmedia.partnershiponai.org/" rel="noopener" target="_blank">Partnership on AI, Responsible Practices for Synthetic Media</a><br>
            3) <a href="https://www.gen-ai.witness.org/" rel="noopener" target="_blank">WITNESS, Prepare, Don’t Panic (deepfake field guide)</a></p>
            </div>
            </div>
            </details>

            <details><summary> <i></i>Malicious AI Misuse</summary>

            <div>
            <div><img alt="A luminous blue security shield icon being breached by aggressive red data streams, representing a cybersecurity attack." loading="lazy" src="https://d1qywhc7l90rsa.cloudfront.net/accounts/165495/images/AI_Misuse.png"></div>

            <p>AI lowers the bar for creating malicious content. This malicious content includes phishing emails, social engineering scripts, and malware. The AI models themselves are at risk through attacks like <a href="https://en.wikipedia.org/wiki/Prompt_injection" target="_blank">prompt injections</a>.</p>

            <p><strong>Example:</strong> A tailored phishing email generated in seconds steals credentials and compromises a school&#x27;s network.</p>


            <table>
            	<thead>
            		<tr>
            			<th>Factor</th>
            			<th>Assessment</th>
            		</tr>
            	</thead>
            	<tbody>
            		<tr>
            			<td><span><i></i><strong>Severity</strong></span></td>
            			<td>High. A compromise can expose sensitive data or disrupt operations.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Exposure</strong></span></td>
            			<td>Broad. Any connected user or system can be a target.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Plausibility</strong></span></td>
            			<td>High. Attack methods and tools are publicly known.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Prevalence</strong></span></td>
            			<td>Rising. Security teams are tracking many new AI-specific vulnerabilities.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Mitigation</strong></span></td>
            			<td>
            			<p><strong>Systemic &amp; Institutional:</strong> Organizations should use threat modeling, strict input filtering, and secure design principles to protect their systems.</p>

            			<p><strong>Individual &amp; Classroom Actions:</strong></p>

            			<ul>
            				<li>Be skeptical. Treat links, code, and attachments with caution.</li>
            				<li>Protect your data. Never give personal credentials to a chatbot.</li>
            				<li>Report threats. Flag malicious outputs to help developers improve safety filters.</li>
            			</ul>
            			</td>
            		</tr>
            	</tbody>
            </table>

            <div>
            <h4><i></i>Quick Activity</h4>

            <p>I dunno. Pay careful attention to your emails.</p>
            </div>

            <div>
            <h5><i></i>Dive Deeper</h5>

            <p>1) <a href="https://csrc.nist.gov/pubs/ai/100/2/e2025/final" rel="noopener" target="_blank">NIST, Adversarial ML Taxonomy (AI 100-2)</a><br>
            2) Contact the Author to suggest some more high quality resources</p>
            </div>
            </div>
            </details>


            <details><summary> <i></i> Data Security, Privacy &amp; Rights </summary>

            <div>
            <div><img alt="Tree of data protected from data harvesting monsters by a glowing shield" loading="lazy" src="https://d1qywhc7l90rsa.cloudfront.net/accounts/165495/images/data_security.png"></div>

            <p>AI applications collect and store personal data and may do so in ways users do not expect. Weak controls can lead to data breaches, re-identification of anonymous data, and illegal use. AI applications can be designed to figure things out about you; even if you are not giving them personal data, your interactions could be analyzed to create a decent profile of you.</p>

            <p><strong>Example:</strong> <a href="https://www.bbc.com/news/articles/cdrkmk00jy0o" target="_blank">Private chats in the chatbot Grok were indexed by Google </a>and became searchable by anyone.  <a href="https://techcrunch.com/2025/07/31/your-public-chatgpt-queries-are-getting-indexed-by-google-and-other-search-engines/" target="_blank">ChatGPT had a similar problem</a>.</p>


            <table>
            	<thead>
            		<tr>
            			<th>Factor</th>
            			<th>Assessment</th>
            		</tr>
            	</thead>
            	<tbody>
            		<tr>
            			<td><span><i></i><strong>Severity</strong></span></td>
            			<td>High. Breaches of sensitive data cause significant harm and legal risk.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Exposure</strong></span></td>
            			<td>Large. Many users and devices handle personal data.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Plausibility</strong></span></td>
            			<td>High. Standard workflows often involve sharing data with cloud tools.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Prevalence</strong></span></td>
            			<td>Common. Privacy incidents happen all the time.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Mitigation</strong></span></td>
            			<td>
            			<p><strong>Systemic &amp; Institutional:</strong> Institutions must practice data minimization, conduct privacy assessments, and comply with laws like FERPA and GDPR.</p>

            			<p><strong>Individual &amp; Classroom Actions:</strong></p>

            			<ul>
            				<li>Do not share secrets. Avoid pasting sensitive personal or financial information into public AI tools.</li>
            				<li>Check the settings. Review an AI&#x27;s privacy policy and opt out of data training when possible.</li>
            				<li>Use fake data. Use anonymized or hypothetical information when experimenting with new tools.</li>
            			</ul>
            			</td>
            		</tr>
            	</tbody>
            </table>

            <div>
            <h4><i></i>Quick Activity</h4>

            <p>Actually read the privacy policy of an AI company to find out what they are doing with your data.</p>
            </div>

            <div>
            <h5><i></i>Dive Deeper</h5>

            <p>1) Let me know if you have suggestions for good quality resources to go here.</p>
            </div>
            </div>
            </details>


            <details><summary> <i></i> Bias, Fairness &amp; Inclusion </summary>

            <div>
            <div><img alt="A robotic hand selecting only one color of stylized human icons from a diverse crowd, illustrating algorithmic bias." loading="lazy" src="https://d1qywhc7l90rsa.cloudfront.net/accounts/165495/images/BiasFairnessInclusion.png"></div>

            <p>AI models can adopt and amplify human biases found in their training data. This affects everything from grading tools and hiring filters to how people are portrayed.</p>

            <p><strong>Example:</strong> An image generator returns stereotyped pictures of &quot;scientists&quot; and under-represents women and people of color.</p>


            <table>
            	<thead>
            		<tr>
            			<th>Factor</th>
            			<th>Assessment</th>
            		</tr>
            	</thead>
            	<tbody>
            		<tr>
            			<td><span><i></i><strong>Severity</strong></span></td>
            			<td>Medium to high. Systematic unfairness hurts opportunities and dignity.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Exposure</strong></span></td>
            			<td>Broad. Popular models are used everywhere for many different tasks.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Plausibility</strong></span></td>
            			<td>High. Bias in AI models is a well-documented problem.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Prevalence</strong></span></td>
            			<td>Frequent. This is especially true in general-purpose models.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Mitigation</strong></span></td>
            			<td>
            			<p><strong>Systemic &amp; Institutional:</strong> Companies should use representative data, test for bias, and design inclusive and accessible products with human oversight.</p>

            			<p><strong>Individual &amp; Classroom Actions:</strong></p>

            			<ul>
            				<li>Test for bias. Actively use prompts with diverse identities and contexts to see what the AI produces.</li>
            				<li>Report it. Use feedback features to report biased outputs to developers.</li>
            				<li>Prompt better. Learn to write prompts that ask for inclusive and counter-stereotypical results.</li>
            			</ul>
            			</td>
            		</tr>
            	</tbody>
            </table>

            <div>
            <h4><i></i>Quick Activity</h4>

            <p>Prompt an image model with role labels like “CEO” or “nurse.” Tally the outputs and discuss the stereotypes you see. Then try to fix them with better prompts.</p>
            </div>

            <div>
            <h5><i></i>Dive Deeper</h5>

            <p>1) <a href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1270.pdf" rel="noopener" target="_blank">NIST, SP 1270: Managing Bias in AI</a><br>
            2) Let me know if you have suggestions for good quality resources to go here.</p>
            </div>
            </div>
            </details>


            <details><summary> <i></i> Accountability, Transparency &amp; Redress </summary>

            <div>
            <div><img alt="Policy document with a magnifying glass symbolizing AI transparency, auditability, and appeals" loading="lazy" src="https://d1qywhc7l90rsa.cloudfront.net/accounts/165495/images/accountability.png"></div>

            <p>When an AI makes a decision, how do we know how it made that decision (transparency), who is responsible for the consequences of the decision (accountability), and how will those impacted by the decision be compensated for harms (redress).</p>

            <p><strong>Examples:</strong> An instructor uses an AI to flag plagiarism and punishes a student based solely on the AI&#x27;s decision. Who is accountable for this decision? A student uses AI to write a report and that report refers to papers that do not exist. Who is accountable for this mistake? An HR manager uses AI to determine a shortlist for interviews. How can he/she know how the AI came up with shortlist?</p>


            <table>
            	<thead>
            		<tr>
            			<th>Factor</th>
            			<th>Assessment</th>
            		</tr>
            	</thead>
            	<tbody>
            		<tr>
            			<td><span><i></i><strong>Severity</strong></span></td>
            			<td>Medium to high. Opaque decisions can wrongly penalize people.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Exposure</strong></span></td>
            			<td>Broad. This affects anyone evaluated or served by an AI system.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Plausibility</strong></span></td>
            			<td>High. Good documentation is often missing when new tech is adopted quickly.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Prevalence</strong></span></td>
            			<td>Mixed. Transparency is improving but remains uneven. Accountability and redress are evolving.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Mitigation</strong></span></td>
            			<td>
            			<p><strong>Organizations:</strong> publish model cards, log decisions, and require human-in-the-loop for impactful calls.</p>

            			<p><strong>Individuals:</strong></p>

            			<ul>
            				<li>Be the human-in-the-loop when possible.</li>
            				<li>Advocate for clear policies and appeal processes.</li>
            				<li>Keep records</li>
            			</ul>
            			</td>
            		</tr>
            	</tbody>
            </table>

            <div>
            <h4><i></i>Quick Activity</h4>

            <p>Transparency: Read the model card of an AI tool you use. Explain its purpose, data sources, and limitations.</p>

            <p>Accountability:</p>
            </div>

            <div>
            <h5><i></i>Dive Deeper</h5>

            <p>1) Recommend some links to me</p>
            </div>
            </div>
            </details>
            </div>
            </div>



                </div><div>
                <div id="gai-wrap">
            <div>
            <h1>AI Risks and Ethical Impacts Part 2</h1>

            <div>
            <details><summary> <i></i> IP, Copyright &amp; Data Sovereignty </summary>

            <div>
            <div><img alt="A glowing copyright symbol being deconstructed into a swirling vortex of digital data, with a robotic arm reaching in." loading="lazy" src="https://d1qywhc7l90rsa.cloudfront.net/accounts/165495/images/IPCopyrightDataSovereignty.png"></div>

            <p>Generative models learn from existing works, including copyrighted material. Their outputs can sometimes mimic an artist&#x27;s style or content too closely, creating legal and ethical conflicts.</p>

            <p><strong>Examples:</strong> (1) <a href="https://www.cbc.ca/news/canada/newfoundland-labrador/meta-ai-local-authors-1.7502766" rel="noopener noreferrer" target="_blank"> Meta used pirated books</a> to train some of its AI models. (2) A music class uses an AI tool that creates songs that sound almost identical to those of a living artist.</p>


            <table>
            	<thead>
            		<tr>
            			<th>Factor</th>
            			<th>Assessment</th>
            		</tr>
            	</thead>
            	<tbody>
            		<tr>
            			<td><span><i></i><strong>Severity</strong></span></td>
            			<td>Medium to high. This can lead to serious legal and ethical problems for creators and institutions.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Exposure</strong></span></td>
            			<td>Broad. This affects anyone doing creative work or publishing.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Plausibility</strong></span></td>
            			<td>High. Models are trained on the public web and are designed to imitate styles.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Prevalence</strong></span></td>
            			<td>Frequent. This issue is at the center of many active lawsuits and policy debates.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Mitigation</strong></span></td>
            			<td>
            			<p><strong>Systemic &amp; Institutional:</strong> Companies should respect license terms, use ethically sourced datasets, and adopt content watermarking to show provenance.</p>

            			<p><strong>Individual &amp; Classroom Actions:</strong></p>

            			<ul>
            				<li>Disclose your use. Follow your institution&#x27;s policy for citing or disclosing the use of AI in your work.</li>
            				<li>Use it as a tool. Let AI help you brainstorm, but ensure the final creative expression is your own.</li>
            				<li>Choose wisely. Favor tools that use openly licensed data.</li>
            			</ul>
            			</td>
            		</tr>
            	</tbody>
            </table>

            <div>
            <h4><i></i>Quick Activity</h4>

            <p>Generate an image “in the style of” an artist. Compare it to their real work. Discuss where inspiration ends and infringement might begin.</p>
            </div>

            <div>
            <h5><i></i>Dive Deeper</h5>

            <p>1) <a href="https://www.copyright.gov/ai/" rel="noopener" target="_blank">U.S. Copyright Office, AI Policy &amp; Registration Guidance</a><br>
            2) <a href="https://www.wipo.int/publications/en/details.jsp?id=4713" rel="noopener" target="_blank">WIPO, Generative AI: Navigating IP (factsheet)</a><br>
            3) <a href="https://c2pa.org/" rel="noopener" target="_blank">C2PA / Content Authenticity Initiative (provenance)</a></p>
            </div>
            </div>
            </details>

            <details><summary> <i></i> Economic &amp; Labor Impacts </summary>

            <div>
            <div><img alt="A split image showing human workers on one side and robots on the other, connected by a glowing digital network." loading="lazy" src="https://d1qywhc7l90rsa.cloudfront.net/accounts/165495/images/economicImpacts.png"></div>

            <p>Generative AI is changing the job market. It can automate some tasks, assist with others, and shift the demand for certain skills, especially for entry-level roles.</p>

            <p><strong>Example:</strong> A marketing firm reduces its need for copywriters after adopting an AI-assisted writing tool, affecting entry level jobs.</p>


            <table>
            	<thead>
            		<tr>
            			<th>Factor</th>
            			<th>Assessment</th>
            		</tr>
            	</thead>
            	<tbody>
            		<tr>
            			<td><span><i></i><strong>Severity</strong></span></td>
            			<td>Medium to high. Job displacement and new inequities can occur.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Exposure</strong></span></td>
            			<td>Broad. This impacts knowledge work and creative fields.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Plausibility</strong></span></td>
            			<td>High. Companies in every sector are adopting AI quickly.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Prevalence</strong></span></td>
            			<td>Growing. Hard evidence of job impacts is limited, but anecdotal evidence is strong.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Mitigation</strong></span></td>
            			<td>
            			<p><strong>Systemic &amp; Institutional:</strong> Organizations should focus on redesigning jobs, upskilling their workforce, and being transparent about automation plans.</p>

            			<p><strong>Individual &amp; Classroom Actions:</strong></p>

            			<ul>
            				<li>Focus on durable skills. Develop critical thinking, creativity, and collaboration abilities that AI cannot replicate.</li>
            				<li>Become the pilot. Learn how to use AI effectively and ethically to augment your work.</li>
            				<li>Stay informed. Pay attention to how AI is changing your field of study or career path.</li>
            			</ul>
            			</td>
            		</tr>
            	</tbody>
            </table>

            <div>
            <h4><i></i>Quick Activity</h4>

            <p>Pick one job, like academic advising. List its core tasks, mark which AI can assist with, and identify which require a human touch.</p>
            </div>

            <div>
            <h5><i></i>Dive Deeper</h5>

            <p>1) <a href="https://eig.org/ai-and-jobs-the-final-word" rel="noopener" target="_blank">EIG, AI and jobs (2025)</a><br>
            2) <a href="https://www.ilo.org/sites/default/files/2025-05/WP140_web.pdf" rel="noopener" target="_blank">ILO, Generative AI and jobs (2025)</a><br>
            3) <a href="https://www.brookings.edu/articles/is-generative-ai-a-job-killer-evidence-from-the-freelance-market" rel="noopener" target="_blank">Brookings, Is generative AI a job killer? (2025)</a><br>
            4) <a href="https://www.weforum.org/publications/the-future-of-jobs-report-2025/" rel="noopener" target="_blank">WEF, Future of Jobs 2025</a></p>
            </div>
            </div>
            </details>

            <details><summary> <i></i> Environment &amp; Supply Chain </summary>

            <div>
            <div><img alt="A data center server rack overgrown with green vines, with a holographic display showing high energy and water use." loading="lazy" src="https://d1qywhc7l90rsa.cloudfront.net/accounts/165495/images/environment_and_supply_chain.png"></div>

            <p>Training and running large AI models uses a lot of energy and water. The hardware itself relies on global supply chains that can have their own environmental and social risks.</p>

            <p><strong>Example:</strong> An AI company builds a large data center which requires a large amount of electricity and water (for cooling). The local community experiences rolling brownouts and minimal water pressure.</p>


            <table>
            	<thead>
            		<tr>
            			<th>Factor</th>
            			<th>Assessment</th>
            		</tr>
            	</thead>
            	<tbody>
            		<tr>
            			<td><span><i></i><strong>Severity</strong></span></td>
            			<td>Medium to high. The environmental impacts are cumulative and global.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Exposure</strong></span></td>
            			<td>Growing. AI is being embedded in more services we use every day.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Plausibility</strong></span></td>
            			<td>High. The demand for AI computing power is surging.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Prevalence</strong></span></td>
            			<td>Increasing. Energy and water use from data centers is a tracked metric.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Mitigation</strong></span></td>
            			<td>
            			<p><strong>Systemic &amp; Institutional:</strong></p>

            			<ul>
            				<li>Design more efficient models.</li>
            				<li>Build green energy sources to meet electrical demand.</li>
            				<li>Choose cold climates for servers.</li>
            				<li>Government protect electrical and water supplies of communities where data centers are being built.</li>
            			</ul>

            			<p><strong>Individual &amp; Classroom Actions:</strong></p>

            			<ul>
            				<li>Be efficient. Use smaller models when possible and avoid running unnecessary AI queries.</li>
            				<li>Choose local models. When feasible, run smaller, open-source models on your own device.</li>
            				<li>Ask questions. Support institutions that are transparent about their AI energy use and sustainability goals.</li>
            			</ul>
            			</td>
            		</tr>
            	</tbody>
            </table>

            <div>
            <h4><i></i>Quick Activity</h4>

            <p>Use the website <a href="https://what-uses-more.com/" rel="noopener noreferrer" target="_blank">What Uses More</a> to compare the amount of energy required to write a book chapter to the amount of energy needed to watch Netflix.</p>
            </div>

            <div>
            <h5><i></i>Dive Deeper</h5>

            <p>1) <a href="https://www.iea.org/reports/energy-and-ai" rel="noopener" target="_blank">IEA, Energy &amp; AI (2025 report &amp; brief)</a><br>
            2) <a href="https.www.sustainabilitybynumbers.com/p/ai-footprint-august-2025" rel="noopener noreferrer" target="_blank">Carbon Footprint of ChatGPT and Gemini (opinion)</a><br>
            3) <a href="https://cloud.google.com/blog/products/infrastructure/measuring-the-environmental-impact-of-ai-inference" rel="noopener noreferrer" target="_blank">Google&#x27;s Own Calculations</a></p>
            </div>
            </div>
            </details>


            <details><summary> <i></i> Monopoly &amp; Market Power </summary>

            <div>
            <div><img alt="Dominant AI company represented by a chess king. Fallen pawns surround it" loading="lazy" src="https://d1qywhc7l90rsa.cloudfront.net/accounts/165495/images/monopoly.png"></div>

            <p>A few large companies control most of the computing power, data, and models for AI. This concentration of power can limit innovation, drive up prices, and lock users into one ecosystem.</p>

            <p><strong>Example:</strong> A vendor bundles an AI suite that forces a school to use one specific cloud provider and a closed set of models.</p>


            <table>
            	<thead>
            		<tr>
            			<th>Factor</th>
            			<th>Assessment</th>
            		</tr>
            	</thead>
            	<tbody>
            		<tr>
            			<td><span><i></i><strong>Severity</strong></span></td>
            			<td>Medium. The risks to innovation, cost, and choice grow over time.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Exposure</strong></span></td>
            			<td>Broad. The market structure affects what tools are available to everyone.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Plausibility</strong></span></td>
            			<td>High. Reports show a few players have massive advantages.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Prevalence</strong></span></td>
            			<td>Under active regulatory review around the world.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Mitigation</strong></span></td>
            			<td>
            			<p><strong>Systemic:</strong> Institutions should pursue multi-vendor strategies, support open standards, and demand data portability from their vendors.</p>

            			<p><strong>Individual:</strong></p>

            			<ul>
            				<li><strong>Support open source.</strong> Experiment with and contribute to open-source AI projects.</li>
            				<li><strong>Stay flexible.</strong> Avoid becoming overly dependent on a single proprietary tool or platform.</li>
            				<li><strong>Advocate for choice.</strong> Encourage your institution to consider a variety of AI tools, including smaller and open-source options.</li>
            			</ul>
            			</td>
            		</tr>
            	</tbody>
            </table>

            <div>
            <h4><i></i>Quick Activity</h4>

            <p>Find at least 3 open-source AI tools and try them out.</p>
            </div>

            <div>
            <h5><i></i>Dive Deeper</h5>

            <p>1) <a href="https://www.gov.uk/government/publications/ai-foundation-models-initial-report" rel="noopener" target="_blank">UK CMA, Foundation Models: Initial Report &amp; 2024 Update</a><br>
            2) <a href="https://www.ftc.gov/policy/advocacy-research/tech-at-ftc/2023/06/generative-ai-raises-competition-concerns" rel="noopener" target="_blank">FTC, Generative AI Raises Competition Concerns</a><br>
            3) Let me know of other good resources.</p>
            </div>
            </div>
            </details>

            <details><summary> <i></i> Simulated Reality</summary>

            <div>
            <div><img alt="A hand holds a pen and is writing, but the skeleton of the hand is an AI controlling what the hand does." loading="lazy" src="https://d1qywhc7l90rsa.cloudfront.net/accounts/165495/images/simulated_reality2.png"></div>

            <p>Interactions with AI can feel as good as the real thing. AI can act like a therapist, a friend, or an antagonist but it is not actually any of those things. It can also produce polished work that lets students skip the hard parts of learning. This replaces moments of growth, creativity, and struggle with a &quot;good enough&quot; substitute.</p>

            <p><strong>Examples: </strong> (1) A user has enjoyable interactions with a chatbot and feels like he/she has developed a relationship with it. When the chatbot is updated to a newer version, the user feels like they have lost a friend. (2) A student submits an AI-written reflection, missing the chance to develop their own voice, judgment, and ideas.</p>


            <table>
            	<thead>
            		<tr>
            			<th>Factor</th>
            			<th>Assessment</th>
            		</tr>
            	</thead>
            	<tbody>
            		<tr>
            			<td><span><i></i><strong>Severity</strong></span></td>
            			<td>Medium. The slow erosion of skills and meaning is a serious long-term risk.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Exposure</strong></span></td>
            			<td>Broad. The temptation to take shortcuts is high.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Plausibility</strong></span></td>
            			<td>High. Easy-to-use tools are always just a click away.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Prevalence</strong></span></td>
            			<td>Increasing. Surveys show widespread use of AI by students.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Mitigation</strong></span></td>
            			<td>
            			<p><strong>Systemic &amp; Institutional:</strong> Educators can design assignments that focus on the process, not just the final product. This includes requiring drafts, oral presentations, and in-class work.</p>

            			<p><strong>Individual &amp; Classroom Actions:</strong></p>

            			<ul>
            				<li>Go through this whole LibGuide and discover how to use AI to support your learning.</li>
            				<li>Reflect on your process. Keep notes on how you solved a problem, not just the solution.</li>
            				<li>Practice in &quot;AI-free zones.&quot; Set aside time for focused thinking and writing without AI assistance.</li>
            			</ul>
            			</td>
            		</tr>
            	</tbody>
            </table>

            <div>
            <h4><i></i>Quick Activity</h4>

            <p>Do a short task twice, once with AI help and once without. Compare the final products, but more importantly, compare your notes on the process.</p>
            </div>

            <div>
            <h5><i></i>Dive Deeper</h5>

            <p>1) <a href="https://www.unesco.org/en/articles/guidance-generative-ai-education-and-research" rel="noopener" target="_blank">UNESCO, Guidance for GenAI in Education &amp; Research</a><br>
            2) <a href="https://library.educause.edu/resources/2024/5/2024-educause-action-plan-ai-policies-and-guidelines" rel="noopener" target="_blank">EDUCAUSE, 2024 Action Plan: AI Policies &amp; Guidelines</a><br>
            3) KEEP READING THIS LIBGUIDE!!!</p>
            </div>
            </div>
            </details>

            <details><summary> <i></i> Harassment &amp; Child Safety </summary>

            <div>
            <div><img alt="Woman looking into mirror which is shattered, ghosts of angry faces surround her" loading="lazy" src="https://d1qywhc7l90rsa.cloudfront.net/accounts/165495/images/harassment.png"></div>

            <p>AI can be used to create and spread abusive content. This includes non-consensual deepfakes and targeted harassment. It can also expose minors to harmful material.</p>

            <p><strong>Example:</strong> A student’s face is put into a sexualized deepfake image by classmates, which then spreads rapidly online.</p>


            <table>
            	<thead>
            		<tr>
            			<th>Factor</th>
            			<th>Assessment</th>
            		</tr>
            	</thead>
            	<tbody>
            		<tr>
            			<td><span><i></i><strong>Severity</strong></span></td>
            			<td>High. The psychological harm and safety risks are severe.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Exposure</strong></span></td>
            			<td>Significant. Anyone with a phone can be targeted or exposed.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Plausibility</strong></span></td>
            			<td>High. The tools are easy to use, and content moderation struggles to keep up.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Prevalence</strong></span></td>
            			<td>Documented. Reports from safety groups show these incidents are rising.</td>
            		</tr>
            		<tr>
            			<td><span><i></i><strong>Mitigation</strong></span></td>
            			<td>
            			<p><strong>Systemic &amp; Institutional:</strong> Platforms must invest in strong safeguards, rapid takedown procedures, and clear pathways to support victims.</p>

            			<p><strong>Individual &amp; Classroom Actions:</strong></p>

            			<ul>
            				<li>Do not create or share harmful content. Understand that doing so causes real harm and can have serious consequences.</li>
            				<li>Report it immediately. If you see abusive content, report it to the platform and a trusted adult or authority.</li>
            				<li>Support victims. Be an ally to those who have been targeted. Do not blame them or share the abusive material.</li>
            			</ul>
            			</td>
            		</tr>
            	</tbody>
            </table>

            <div>
            <h4><i></i>Quick Activity</h4>

            <p>Role-play a reporting scenario. A student discloses a deepfake. Practice the next steps: capturing evidence, reporting to the platform, and escalating to school staff.</p>
            </div>

            <div>
            <h5><i></i>Dive Deeper</h5>

            <p>1) <a href="https://www.weprotect.org/" rel="noopener" target="_blank">WeProtect Global Alliance</a><br>
            2) What other links do you suggest?</p>
            </div>
            </div>
            </details>
            </div>


            <div>
            <h5><i></i>Connecting the Dots</h5>

            <p>These risks are not separate problems. They are an interconnected web of challenges. Seeing the links between them is key to understanding AI safety.Here are a few examples:</p>

            <ul>
            	<li>A few companies with <strong>Monopoly Power</strong> can control most AI models. This can worsen <strong>Bias &amp; Fairness</strong> issues by limiting diverse options and hurt <strong>Accountability</strong> because closed systems are hard to audit.</li>
            	<li>Poor <strong>Data Security</strong> leads to breaches. This enables <strong>Security Threats</strong> like personalized phishing scams, which then fuel <strong>Information Harms</strong> by making fake content more believable.</li>
            </ul>

            <p>Your Turn: What other connections can you find? Think about how a lack of <strong>Transparency</strong> might affect <strong>Simulated Reality</strong> in learning. How could a focus on the <strong>Environment</strong> change which models get built? Exploring these connections is a powerful way to build your understanding of the negative impacts of generative AI.</p>
            </div>
            </div>
            </div>


                </div><div>
                <div id="gai-wrap">
            <div>
            <div>
            <h1><i></i>Other Resources</h1>

            <p>This is a list of a few resources I&#x27;ve found helpful for understanding responsible AI technology use.</p>
            </div>

            <div>
            <h3><a href="https://datadetoxkit.org/en/home/" rel="noopener noreferrer" target="_blank">Data Detox Kit</a></h3>

            <p>A toolkit developed by Tactical Tech designed to help individuals manage their digital privacy, security, and overall digital wellbeing (with a more recent focus on AI). The kit provides practical, everyday steps to gain more control over your online life, covering aspects like screen time, app usage, passwords, and understanding data trails. </p>
            </div>

            <div>
            <h3><a href="https://uottawa.libguides.com/generative_ai/costs" rel="noopener noreferrer" target="_blank">Costs of Generative AI (University of Ottawa)</a></h3>

            <p>An in-depth examination of the various costs and harms associated with generative AI technologies. This resource explores critical questions about what level of harm from AI might outweigh its benefits, covering environmental impacts, labor exploitation, bias amplification, and social inequities. Features Rebecca Sweetman&#x27;s comprehensive analysis of Large Language Model harms, making it essential reading for understanding AI&#x27;s broader societal implications.</p>
            </div>

            <div>
            <h3><a href="https://www.humanetech.com/podcast" rel="noopener noreferrer" target="_blank">Your Undivided Attention Podcast</a></h3>

            <p>A thought-provoking podcast by the Center for Humane Technology that explores how technology is reshaping society and what we can do to ensure it serves humanity&#x27;s best interests. Hosted by Tristan Harris and Aza Raskin, the show examines the intersection of technology and humanity, offering insights into creating a more humane digital future through thoughtful design and policy.</p>
            </div>

            <div>
            <h3><a href="https://cte.ku.edu/addressing-bias-ai" rel="noopener noreferrer" target="_blank">Addressing Bias in AI (University of Kansas)</a></h3>
            </div>

            <div>
            <p>Educational materials designed to help instructors and students understand and discuss the biases inherent in generative AI systems. Explores various types of bias (cognitive, cultural, demographic, linguistic, and more), provides practical classroom activities for examining AI bias in both text and images, and offers strategies for critical evaluation of AI-generated content. Includes extensive resources and readings for deeper exploration.</p>
            </div>

            <div>
            <h3><a href="https://nmdprojects.net/learnwithai_www/impactrisk/" rel="noopener noreferrer" target="_blank">IMPACT RISK Framework</a></h3>

            <p>A structured framework for understanding and evaluating the potential risks and impacts of AI systems. This resource provides a systematic approach to assessing AI technologies across multiple dimensions, helping users develop critical thinking skills for responsible AI adoption and implementation.</p>
            </div>

            <div>
            <h5><i></i>Share Your Recommendations</h5>

            <p>Know of other valuable resources for AI literacy, digital wellbeing, or responsible technology use? I&#x27;d love to hear about them! Feel free to reach out with your suggestions so this collection can continue to grow and serve the community better.</p>
            </div>
            </div>
            </div>


                </div>
        </section>
        <p class="gai-end-txt">Unless otherwise stated, this page and <a href="pillars-of-ai-literacy.html">AI Literacy for Students</a> © 2025 by David Williams is licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International</a><span class="gai-cc-icons"><img loading="lazy" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg" alt="Creative Commons icon" /><img loading="lazy" src="https://mirrors.creativecommons.org/presskit/icons/by.svg" alt="Attribution icon" /><img loading="lazy" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg" alt="Non-Commercial icon" /><img loading="lazy" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg" alt="Share Alike icon" /></span></p>
        </div>
    </main>
</div>
</body>
</html>
