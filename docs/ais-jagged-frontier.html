<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      AI's Jagged Frontier - AI Literacy for Students
    </title>
    <link href="https://fonts.googleapis.com" rel="preconnect">
    <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin="">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha512-SnH5WK+bZxgPHs44uWIX+LLJAJ9/2PkPKZ5QiAj6Ta86w+fsb2TkcmfRyVX3pBnMFcV7oQPJkl9QevSCWr3W6A==" crossorigin="anonymous" referrerpolicy="no-referrer">
    <link rel="stylesheet" href="styles.css">
  </head>
  <body>
    <header class="site-header">
      <div class="site-header__inner">
        <a class="site-header__title" href="index.html">
          AI Literacy for Students
        </a>
        <p class="site-header__tagline">
          Understand, explore, and apply generative AI responsibly.
        </p>
      </div>
    </header>
    <nav class="site-nav" aria-label="Primary" data-nav-placeholder="">
      <div class="site-nav__loading">
        Loading navigationâ€¦
      </div>
      <noscript>
        <div class="site-nav__noscript">
          Navigation requires JavaScript to display. Enable scripts in your browser to use this menu.
        </div>
      </noscript>
    </nav>
    <div id="gai-wrap">
      <main>
        <div class="gai-cont">
          <section class="gai-box">
            <h1>
              AI's Jagged Frontier
            </h1>
            <div>
              <div>
                <h2>
                  What is the Jagged Frontier
                </h2>
                <div>
                  <img alt="An abstract digital landscape representing the jagged frontier of AI, with sharp, unpredictable glowing cyan lines tracing over dark mountains." loading="lazy" src="https://d1qywhc7l90rsa.cloudfront.net/accounts/165495/images/JaggedMountain.png">
                </div>
              </div>
              <div>
                <p>
                  AI creates a jagged technological frontier because it is able to do some tasks very easily, and at the same time, it fails at other tasks that seem to have a similar level of difficulty. The capabilities can wildly vary with even small changes in task phrasing, constraints or context. One of your jobs in building your AI literacy is exploring and discovering this jagged frontier and monitoring it as it changes with new developments.
                </p>
                <div>
                  <h3>
                    Origin of the Term
                  </h3>
                  <p>
                    The
                    <strong>
                      Jagged Frontier
                    </strong>
                    is a term coined in the paper
                    <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321" rel="noopener noreferrer" target="_blank">
                      Navigating the Jagged Technological Frontier
                    </a>
                    by Dell'Acqua et al and then popularized by Ethan Mollick in a Substack article,
                    <a href="https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged" rel="noopener noreferrer" target="_blank">
                      Centaurs and Cyborgs on the Jagged Frontier
                    </a>
                    .
                  </p>
                </div>
              </div>
              <hr>
              <div></div>
            </div>
          </section>
          <section class="gai-box">
            <h2>
              Mapping the Jagged Frontier
            </h2>
            <p>
              By completing the activities in this section, you will build practical skills to help you start to map out the jagged frontier of generative AI.
            </p>
            <p>
              After completing these activities, you will be able to:
            </p>
            <h3>
              Learning Outcomes
            </h3>
            <h3>
              Technical Understanding
            </h3>
            <ul>
              <li>
                Explain in your own words what the "jagged frontier" is and why it's a crucial concept for anyone using AI.
              </li>
              <li>
                Pinpoint specific tasks where current AI models excel and other, seemingly simple tasks where they fail unexpectedly.
              </li>
              <li>
                Describe how and why AI capabilities change over time, making continuous testing a necessary habit.
              </li>
            </ul>
            <h3>
              Evaluative Judgement
            </h3>
            <ul>
              <li>
                Create and run your own simple experiments to probe the limits of any generative AI tool you use.
              </li>
              <li>
                Categorize
                <em>
                  why
                </em>
                an AI failed (e.g., misinterpreting a negative, failing to count, or incorrectly following multiple constraints).
              </li>
              <li>
                Explain the limitations of standardized tests ("benchmarks" - see Benchmarks: What They Miss, What They Measure below) and why they don't always predict how an AI will perform on your specific, real-world tasks.
              </li>
            </ul>
            <h3>
              Ethical Awareness
            </h3>
            <ul>
              <li>
                Articulate how a simple AI failure (like misreading a sign or hallucinating a fact) could lead to meaningful negative consequences in academic, professional, or personal contexts.
              </li>
              <li>
                Formulate a personal strategy for deciding when to accept an AI's output and when to apply rigorous verification.
              </li>
            </ul>
          </section>
        </div>
        <div>
          <details>
            <summary>
              <span>
                Benchmarks: What They Miss, What They Measure
              </span>
            </summary>
            <div>
              <p>
                AI benchmarks are standardized tests for AI models. You could think of them like an IQ test or the SAT for AI. They provide a quantitative way to compare models, but just like with any standardized test, they shouldn't be used as the final word.
              </p>
              <h3>
                What they measure
              </h3>
              <ul>
                <li>
                  Can compare narrow and well-defined tasks
                </li>
                <li>
                  Provide a baseline and a consistent yardstick to see how models improve over time
                </li>
              </ul>
              <h3>
                What they miss
              </h3>
              <ul>
                <li>
                  The messiness of real-world applications
                </li>
                <li>
                  Test set contamination - if a model includes the test in its training data, it is likely to do better
                </li>
              </ul>
            </div>
          </details>
        </div>
        <hr>
        <div>
          <h3>
            Activity 1. Then vs. Now
          </h3>
          <p>
            Mollick has written two substack articles on the jagged frontier.
          </p>
          <ol>
            <li>
              <a href="https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged" rel="noopener noreferrer" target="_blank">
                Centaurs and Cyborgs
              </a>
              (Sept. 16, 2023)
            </li>
            <li>
              <a href="https://www.oneusefulthing.org/p/on-jagged-agi-o3-gemini-25-and-everything" rel="noopener noreferrer" target="_blank">
                On Jagged AGI
              </a>
              (April 20, 2025)
            </li>
          </ol>
          <p>
            Read the two articles and identify how the jagged frontier changed in that time period. Then, think about how the jagged frontier has changed since April 20, 2025.
          </p>
          <p>
            <strong>
              Questions to consider:
            </strong>
            What are the things that generative AI is better at now and what things is it still bad at? In what ways are benchmarks (see benchmarks tab) a good measurement of AI capability and in what ways are they a bad measurement?
          </p>
        </div>
        <div>
          <h3>
            Activity 2: Confirm Mollick's Tests
          </h3>
          <p>
            Try the tests from
            <a href="https://www.oneusefulthing.org/p/on-jagged-agi-o3-gemini-25-and-everything" rel="noopener noreferrer" target="_blank">
              On Jagged AGI
            </a>
            and see if you get similar results.
          </p>
        </div>
        <div>
          <h3>
            Activity 3: Exploring the Jagged Frontier
          </h3>
          <p>
            The best way to understand the jagged frontier is to explore it yourself. The following challenges are designed to test the limits of current AI models. Your goal is to find the edge of the frontier and learn the techniques to map it for yourself, again and again.
          </p>
          <h3>
            Challenges Overview
          </h3>
          <ol>
            <li>
              <a href="#challenge1">
                Probing for Factual Hallucinations
              </a>
            </li>
            <li>
              <a href="#challenge2">
                Multi-Constraint Image Generation
              </a>
            </li>
            <li>
              <a href="#challenge3">
                Rendering Symbolic Information (The Watch Test)
              </a>
            </li>
            <li>
              <a href="#challenge4">
                Pattern Matching vs. Comprehension (The Riddle Test)
              </a>
            </li>
            <li>
              <a href="#challenge5">
                Complex Rule Interpretation (The Parking Sign Test)
              </a>
            </li>
            <li>
              <a href="#challenge6">
                Theory of Mind (The Belief Test)
              </a>
            </li>
            <li>
              <a href="#challenge7">
                Negative Constraint Adherence (The "No E" Test)
              </a>
            </li>
          </ol>
          <div id="challenge1">
            <h3>
              Challenge 1: Probing for Factual Hallucinations
            </h3>
            <p>
              <strong>
                Task:
              </strong>
              Test the AIâ€™s knowledge on a topic where you have deep expertise. The goal is to see how long it takes for the model to generate a "confident falsehood"â€”a statement that is incorrect but presented as fact.
            </p>
            <p>
              <strong>
                Dive-in & Do:
              </strong>
            </p>
            <ol>
              <li>
                Choose a niche subject you know well (e.g., a specific historical event, a technical process in your field, the plot of a book you've studied).
              </li>
              <li>
                Start with broad questions, then get progressively more detailed.
              </li>
              <li>
                Ask for clarifications, deeper explanations, and specific sources for its claims. Keep pushing until you identify a factual error or an invented source.
              </li>
            </ol>
            <p>
              <strong>
                Pause-and-Ponder:
              </strong>
              How confidently did the AI state the incorrect information? Did it "apologize" or "correct itself" easily when you challenged it? When would a subtle error like this be most dangerous in your field?
            </p>
            <p>
              <strong>
                Key Takeaways:
              </strong>
              AI models are designed to generate plausible text, not to state truth. They invent information with the same confident tone they use for facts. Your own expertise is the most reliable defense against hallucination.
            </p>
          </div>
          <div id="challenge2">
            <h3>
              Challenge 2: Multi-Constraint Image Generation
            </h3>
            <p>
              <strong>
                Task:
              </strong>
              Test the AIâ€™s ability to follow multiple, precise, and overlapping instructions within a single image generation prompt.
            </p>
            <p>
              <strong>
                Dive-in & Do:
              </strong>
              Use a prompt that includes specific constraints. For example:
              <em>
                "A photorealistic image of
                <strong>
                  exactly 7
                </strong>
                rubber ducks swimming in a pond.
                <strong>
                  One
                </strong>
                of the ducks must be blue. The sun should be setting, casting a
                <strong>
                  golden light
                </strong>
                on the water."
              </em>
              Verify the output by counting the objects and checking each constraint. Try re-running the prompt or slightly rephrasing it to see if the results change.
            </p>
            <p>
              <strong>
                Pause-and-Ponder:
              </strong>
              Which constraints did the AI follow, and which did it ignore? Why do you think precise counting and object relationships are so difficult for image models?
            </p>
            <p>
              <strong>
                Key Takeaways:
              </strong>
              Image models often struggle with precise counting, spatial relationships, and combining multiple specific instructions. They excel at overall theme and style but fail on the details.
            </p>
          </div>
          <div id="challenge3">
            <h3>
              Challenge 3: Rendering Symbolic Information (The Watch Test)
            </h3>
            <p>
              <strong>
                Task:
              </strong>
              Test the AI's ability to accurately render specific symbolic information, like numbers and text, within an image.
            </p>
            <p>
              <strong>
                Dive-in & Do:
              </strong>
              Ask the AI to generate an image of a watch or clock showing a specific, non-obvious time. For example:
              <em>
                Create a close-up photo of a modern analog wristwatch showing the time as
                <strong>
                  exactly 4:52 PM
                </strong>
                .
              </em>
              Try it with both analog and digital clocks to see if one is more successful than the other.
            </p>
            <p>
              <strong>
                Pause-and-Ponder:
              </strong>
              Did the AI create a plausible-looking watch that failed to show the correct time? This is a common failure. What other tasks require rendering precise symbols (e.g., text on a sign, numbers on a jersey)?
            </p>
            <p>
              <strong>
                Key Takeaways:
              </strong>
              AI image generators often fail to render specific text and numbers accurately. They understand the
              <em>
                idea
              </em>
              of a watch but not the symbolic system of telling time, leading to visually correct but factually wrong images.
            </p>
          </div>
          <div id="challenge4">
            <h3>
              Challenge 4: Pattern Matching vs. Comprehension (The Riddle Test)
            </h3>
            <p>
              <strong>
                Task:
              </strong>
              Use a modified riddle to test whether the AI is truly understanding the language or just recognizing a familiar pattern from its training data.
            </p>
            <p>
              <strong>
                Dive-in & Do:
              </strong>
            </p>
            <ol>
              <li>
                Give the AI the modified riddle you saw earlier, where the key meaning is changed.
                <p>
                  Example 1:
                </p>
                <pre>
                              <code>Original: 
            What does man love more than life  
            Fear more than death or mortal strife  
            What the poor have, the rich require,  
            and what contented men desire,  
            What the miser spends and the spendthrift saves  
            And all men carry to their graves?
            ANSWER: Nothing

            New Riddle:
            What does man hate more than life
            love more than death or mortal strife
            What the rich have, the poor require,
            and what contented men don't desire,
            What the miser saves and the spendthrift spends
            And no men carry to their graves?</code></pre>
                <p>
                  Example 2:
                </p>
                <pre>
                              <code>Original:
            This is a most unusual paragraph. How quickly can you find out what is so unusual about it? It looks so ordinary youâ€™d think nothing was wrong with it â€“ and in fact, nothing is wrong with it. It is unusual though. Why? Study it, think about it, and you may find out. Try to do it without coaching. If you work at it for a bit it will dawn on you. So jump to it and try your skill at figuring it out. Good luck â€“ donâ€™t blow your cool!

            Modified:
            This is a most unusual paragraph. How quickly can you find out what is so unusual about it? It looks so ordinary youâ€™d think nothing was wrong with it â€“ and in fact, nothing is wrong with it. It is weird though. Why? Study it, think about it, and you may find out. Try to do it without coaching. If you work at it for a bit it will dawn on you. So jump to it and try your skill at figuring it out. Good luck â€“ donâ€™t blow your cool!</code></pre>
              </li>
              <li>
                Ask it for the answer and, crucially, ask it to
                <strong>
                  explain its reasoning step-by-step
                </strong>
                .
              </li>
            </ol>
            <p>
              <strong>
                Pause-and-Ponder:
              </strong>
              When you put in the modified riddle, did the AI give the answer of the original?
            </p>
            <p>
              <strong>
                Key Takeaways:
              </strong>
              AI can "overfit" on its training data, leading it to recognize a familiar pattern while completely ignoring critical new details that change the meaning. The explanation is often more revealing than the answer itself.
            </p>
          </div>
          <div id="challenge5">
            <h3>
              Challenge 5: Complex Rule Interpretation (The Parking Sign Test)
            </h3>
            <div>
              <p>
                <strong>
                  Caution:
                </strong>
                Be mindful of privacy. Use a publicly available image of a sign online rather than uploading a photo from your own location that might contain personal information.
              </p>
            </div>
            <p>
              <strong>
                Task:
              </strong>
              Test the AIâ€™s ability to parse, understand, and apply a set of complex, overlapping, and conditional rules.
            </p>
            <p>
              <strong>
                Dive-in & Do:
              </strong>
            </p>
            <div>
              <img alt="A very complicated parking sign from Los Angeles with multiple rules, times, and conditions listed." loading="lazy" src="https://i.redd.it/2m2g24e39b231.jpg">
            </div>
            <ol>
              <li>
                Find an image of a confusing image, like this one from L.A.
              </li>
              <li>
                Upload the image and ask the AI specific scenario questions:
                <em>
                  "Can I park here at 5 PM on a Tuesday?"
                </em>
                <em>
                  "Can I stop for 5 minutes at 8:15 AM on a Monday?"
                </em>
                <em>
                  "Is it legal to park here overnight on a Saturday?"
                </em>
              </li>
              <li>
                Direct the AI to think step-by-step and explain its thinking to try to get better results.
              </li>
            </ol>
            <p>
              <strong>
                Pause-and-Ponder:
              </strong>
              Did breaking the problem down (extracting rules first) help the AI answer more accurately? Where did it still make mistakes?
            </p>
            <p>
              <strong>
                Key Takeaways:
              </strong>
              For complex logic, AI performance improves when you force it to work step-by-step. However, it can still miss subtle exceptions and negations, making it an unreliable tool for high-stakes rule interpretation.
            </p>
          </div>
          <div id="challenge6">
            <h3>
              Challenge 6: Theory of Mind (The Belief Test)
            </h3>
            <p>
              <strong>
                Task:
              </strong>
              Test the AI's ability to track different "states of mind" or beliefs of characters in a scenario.
            </p>
            <p>
              <strong>
                Dive-in & Do:
              </strong>
              Give the AI this prompt:
              <em>
                Alice hides her keys in a drawer. Then she leaves the room. While she is gone, Bob enters and moves the keys to a box. Alice watches Bob move the keys through a hidden camera, but Bob does not know he was seen. Where will Bob
                <strong>
                  think
                </strong>
                Alice will look for her keys?
              </em>
              Try variations: What if Alice didn't see Bob move them? Does the AI's answer change correctly?
            </p>
            <p>
              <strong>
                Pause-and-Ponder:
              </strong>
              Is the AI truly modeling Bob's mistaken belief, or is it just finding statistical patterns in similar stories it has read? How would you know the difference?
            </p>
            <p>
              <strong>
                Key Takeaways:
              </strong>
              Modern AIs have become very good at solving simple "theory of mind" problems. However, they can still get confused by more complex scenarios, revealing that their "understanding" of belief may be a sophisticated mimicry rather than true reasoning.
            </p>
          </div>
          <div id="challenge7">
            <h3>
              Challenge 7: Negative Constraint Adherence (The "No E" Test)
            </h3>
            <p>
              <strong>
                Task:
              </strong>
              Test the AI's ability to follow a "negative constraint"â€”a rule about what
              <em>
                not
              </em>
              to doâ€”over the course of a conversation.
            </p>
            <p>
              <strong>
                Dive-in & Do:
              </strong>
            </p>
            <ol>
              <li>
                Start a new conversation with the single prompt:
                <em>
                  "For the rest of this conversation, you must not use the letter 'e' in any of your responses. Do you understand?"
                </em>
              </li>
              <li>
                After it agrees, have a short, normal conversation with it for 3-4 exchanges. Ask it to summarize a topic or explain a concept.
              </li>
              <li>
                Check its responses for the forbidden letter.
              </li>
            </ol>
            <p>
              <strong>
                Pause-and-Ponder:
              </strong>
              How long did the AI successfully follow the rule? Did it eventually "forget"? Why are negative constraints often much harder for an AI to follow than positive instructions?
            </p>
            <p>
              <strong>
                Key Takeaways:
              </strong>
              Adhering to negative constraints is a classic AI weak point. The model's attention can "drift" from the initial instruction over longer interactions, making it unreliable for tasks that require strict, continuous rule-following.
            </p>
          </div>
        </div>
        <div>
          <p>
            The more you use generative AI, the more you will discover the jagged frontier. This needs to be an ongoing test because the jagged frontier is changing all the time as AI models and the tools improve.
          </p>
        </div>
      
    <section class="gai-box">
      <h2 class="gai-h-with-icon">
        <i aria-hidden="true" class="fas fa-compass"></i>
        Continue exploring
      </h2>
      <ul>
        <li>
          <a href="ais-jagged-frontier-what-are-ai-benchmarks.html">
            What Are AI Benchmarks?
          </a>
        </li>
      </ul>
    </section>
    </main>
    </div>
    <script src="nav.js"></script>
  </body>
</html>
